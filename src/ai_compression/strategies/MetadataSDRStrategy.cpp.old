#include "MetadataSDRStrategy.hpp"
#include <algorithm>
#include <cmath>
#include <iostream>
#include <random>
#include <unordered_map>
#include <bitset>
#include <sstream>
#include <iomanip>
#include <set>

namespace CortexAICompression {

MetadataSDRStrategy::MetadataSDRStrategy(float sparsity, size_t sdrWidth)
    : sparsity_(sparsity), sdrWidth_(sdrWidth) {
    // Validate parameters
    if (sparsity <= 0.0f || sparsity >= 1.0f) {
        throw std::invalid_argument("Sparsity must be between 0 and 1");
    }
    if (sdrWidth_ == 0) {
        throw std::invalid_argument("SDR width must be greater than 0");
    }
}

std::vector<std::byte> MetadataSDRStrategy::compress(const ModelSegment& segment) const {
    // Support both metadata and graph structure segments
    if (segment.type != SegmentType::METADATA_JSON && segment.type != SegmentType::GRAPH_STRUCTURE_PROTO) {
        throw CompressionError("MetadataSDRStrategy only supports metadata and graph structure segments");
    }
    
    std::cerr << "Compressing " << (segment.type == SegmentType::METADATA_JSON ? "metadata" : "graph structure") 
              << " with reversible SDR encoding\n";
    std::cerr << "  Using sparsity: " << sparsity_ << ", SDR width: " << sdrWidth_ << "\n";
    
    try {
        std::vector<size_t> indices;
        std::vector<std::byte> compressedOutput;
        
        // Handle graph structure data differently than metadata
        bool isDirectStorage = false;
        const bool isVeryLargeData = segment.data.size() > 1024 * 1024; // > 1MB
        
        if (segment.type == SegmentType::GRAPH_STRUCTURE_PROTO) {
            // For binary protobuf data, we need to ensure exact byte-level preservation
            indices = encodeBinaryData(segment.data);
            
            // Check if we're using the direct storage mode for very large data
            if (isVeryLargeData && indices.size() == 2 && indices[0] == sdrWidth_) {
                isDirectStorage = true;
                // Store a flag indicating this is direct storage mode
                compressedOutput.push_back(static_cast<std::byte>(2)); // 2 = direct binary storage
                
                // For very large data, we'll store it directly with minimal overhead
                std::cerr << "  Using direct storage for large binary data (" << segment.data.size() << " bytes)" << std::endl;
            } else {
                // Store a flag indicating this is binary data (not string)
                compressedOutput.push_back(static_cast<std::byte>(1)); // 1 = binary mode
            }
        } else {
            // For metadata, convert to string and use string encoding
            std::string metadataStr(reinterpret_cast<const char*>(segment.data.data()), segment.data.size());
            indices = encodeString(metadataStr);
            
            // Store a flag indicating this is string data
            compressedOutput.push_back(static_cast<std::byte>(0)); // 0 = string mode
        }
        
        if (isDirectStorage) {
            // For direct storage mode, just append the original data
            // with minimal overhead - we've already added the mode flag
            
            // Store original data size (for verification during decompression)
            for (size_t i = 0; i < sizeof(size_t); i++) {
                compressedOutput.push_back(static_cast<std::byte>((segment.data.size() >> (i * 8)) & 0xFF));
            }
            
            // Store original data directly
            compressedOutput.insert(compressedOutput.end(), segment.data.begin(), segment.data.end());
            
            std::cerr << "  Stored directly with " << (compressedOutput.size() - segment.data.size()) 
                      << " bytes of overhead" << std::endl;
        } else {
            // Standard SDR encoding for normal-sized data
            std::cerr << "  Encoded to " << indices.size() << " active bits\n";
            
            // Store SDR width
            for (size_t i = 0; i < sizeof(size_t); i++) {
                compressedOutput.push_back(static_cast<std::byte>((sdrWidth_ >> (i * 8)) & 0xFF));
            }
            
            // Store number of indices
            size_t numIndices = indices.size();
            for (size_t i = 0; i < sizeof(size_t); i++) {
                compressedOutput.push_back(static_cast<std::byte>((numIndices >> (i * 8)) & 0xFF));
            }
            
            // Store indices using varint encoding
            for (size_t index : indices) {
                // Simple varint encoding
            while (index >= 0x80) {
                compressedOutput.push_back(static_cast<std::byte>((index & 0x7F) | 0x80));
                index >>= 7;
            }
            compressedOutput.push_back(static_cast<std::byte>(index));
        }
        
        // Store original data length for verification
        size_t dataLength = segment.data.size();
        for (size_t i = 0; i < sizeof(size_t); i++) {
            compressedOutput.push_back(static_cast<std::byte>((dataLength >> (i * 8)) & 0xFF));
        }
        
        // For binary data, store a checksum for verification
        if (segment.type == SegmentType::GRAPH_STRUCTURE_PROTO) {
            // Simple checksum - sum of all bytes
            uint32_t checksum = 0;
            for (const auto& b : segment.data) {
                checksum += static_cast<uint8_t>(b);
            }
            
            // Store checksum
            for (size_t i = 0; i < sizeof(uint32_t); i++) {
                compressedOutput.push_back(static_cast<std::byte>((checksum >> (i * 8)) & 0xFF));
            }
        }
        
        std::cerr << "  Compressed from " << segment.data.size() 
                  << " bytes to " << compressedOutput.size() << " bytes (" 
                  << (compressedOutput.size() * 100.0 / segment.data.size()) 
                  << "% of original)\n";
        
        return compressedOutput;
    } catch (const std::exception& e) {
        throw CompressionError(std::string("Failed to compress: ") + e.what());
    }
}

std::vector<std::byte> MetadataSDRStrategy::decompress(
    const std::vector<std::byte>& compressedData,
    SegmentType originalType,
    size_t originalSize) const {
    
    // Support both metadata and graph structure segments
    if (originalType != SegmentType::METADATA_JSON && originalType != SegmentType::GRAPH_STRUCTURE_PROTO) {
        throw CompressionError("MetadataSDRStrategy only supports metadata and graph structure segments");
    }
    
    try {
        std::cerr << "Decompressing " << (originalType == SegmentType::METADATA_JSON ? "metadata" : "graph structure") 
                  << " with reversible SDR decoding\n";
        
        // Extract header information
        size_t offset = 0;
        
        // Read encoding mode (0 = string, 1 = binary, 2 = direct storage)
        uint8_t encodingMode = static_cast<uint8_t>(compressedData[offset++]);
        bool isBinaryMode = encodingMode == 1;
        bool isDirectStorage = encodingMode == 2;
        
        // Read SDR width
        size_t storedSDRWidth = 0;
        for (size_t i = 0; i < sizeof(size_t); i++) {
            storedSDRWidth |= static_cast<size_t>(compressedData[offset++]) << (i * 8);
        }
        
        // Read number of indices
        size_t numIndices = 0;
        for (size_t i = 0; i < sizeof(size_t); i++) {
            numIndices |= static_cast<size_t>(compressedData[offset++]) << (i * 8);
        }
        
        // Read indices
        std::vector<size_t> indices;
        indices.reserve(numIndices);
        
        for (size_t i = 0; i < numIndices; i++) {
            // Decode varint
            size_t value = 0;
            int shift = 0;
            
            while (offset < compressedData.size()) {
                std::byte currentByte = compressedData[offset++];
                value |= (static_cast<size_t>(currentByte) & 0x7F) << shift;
                
                if ((static_cast<uint8_t>(currentByte) & 0x80) == 0) {
                    break;
                }
                
                shift += 7;
                if (shift >= 64) {
                    throw CompressionError("Varint overflow during decompression");
                }
            }
            
            indices.push_back(value);
        }
        
        // Read original data length
        size_t dataLength = 0;
        for (size_t i = 0; i < sizeof(size_t); i++) {
            dataLength |= static_cast<size_t>(compressedData[offset++]) << (i * 8);
        }
        
        std::vector<std::byte> decompressedData;
        
        if (isDirectStorage) {
            // For direct storage mode, read the data directly
            std::cerr << "  Using direct storage mode for large binary data" << std::endl;
            
            // Read the original data size (for verification)
            size_t storedDataSize = 0;
            for (size_t i = 0; i < sizeof(size_t); i++) {
                storedDataSize |= static_cast<size_t>(compressedData[offset++]) << (i * 8);
            }
            
            // Verify data size
            if (offset + storedDataSize > compressedData.size()) {
                throw CompressionError("Direct storage data incomplete");
            }
            
            // Extract the data directly
            decompressedData.resize(storedDataSize);
            std::copy(compressedData.begin() + offset, 
                      compressedData.begin() + offset + storedDataSize, 
                      decompressedData.begin());
            
            std::cerr << "  Successfully extracted " << decompressedData.size() << " bytes directly" << std::endl;
        } else if (isBinaryMode) {
            // For binary mode, read checksum
            uint32_t storedChecksum = 0;
            for (size_t i = 0; i < sizeof(uint32_t) && offset < compressedData.size(); i++) {
                storedChecksum |= static_cast<uint32_t>(compressedData[offset++]) << (i * 8);
            }
            
            // Decode binary data from indices
            decompressedData = decodeBinaryData(indices, dataLength);
            
            // Verify checksum
            uint32_t calculatedChecksum = 0;
            for (const auto& b : decompressedData) {
                calculatedChecksum += static_cast<uint8_t>(b);
            }
            
            if (calculatedChecksum != storedChecksum) {
                std::cerr << "  Warning: Checksum mismatch during decompression. "
                          << "Expected: " << storedChecksum 
                          << ", Got: " << calculatedChecksum << "\n";
            }
        } else {
            // For string mode, decode string from indices
            std::string decodedStr = decodeString(indices);
            
            // Verify length matches
            if (std::abs(static_cast<long>(decodedStr.length()) - static_cast<long>(dataLength)) > dataLength * 0.1) {
                std::cerr << "  Warning: Decompressed data length " << decodedStr.length() 
                          << " differs significantly from original length " << dataLength << "\n";
            }
            
            // Convert string to bytes
            decompressedData.reserve(decodedStr.size());
            for (char c : decodedStr) {
                decompressedData.push_back(static_cast<std::byte>(c));
            }
        }
        
        std::cerr << "  Successfully decompressed to " 
                  << decompressedData.size() << " bytes\n";
        
        return decompressedData;
    } catch (const std::exception& e) {
        throw CompressionError(std::string("Failed to decompress: ") + e.what());
    }
}

// String encoding/decoding methods
std::vector<size_t> MetadataSDRStrategy::encodeString(const std::string& str) const {
    // Calculate number of active bits based on sparsity and string length
    size_t numActiveBits = std::max(size_t(1), static_cast<size_t>(str.length() * 8 * sparsity_));
    
    // Use a deterministic hash-based approach for encoding
    std::vector<size_t> indices;
    indices.reserve(numActiveBits);
    
    // Generate a set of indices based on character values and positions
    for (size_t i = 0; i < str.length(); i++) {
        // Use character value and position to generate multiple indices
        unsigned char c = str[i];
        
        // Generate multiple indices per character to create distributed representation
        for (size_t j = 0; j < 4; j++) {  // 4 indices per character for better distribution
            // Create a hash from character, position, and salt value j
            size_t hash = (c * 31 + i) * 17 + j * 257;
            size_t index = hash % sdrWidth_;
            
            // Add to indices if not already present
            if (std::find(indices.begin(), indices.end(), index) == indices.end()) {
                indices.push_back(index);
                
                // Stop if we've reached the target number of active bits
                if (indices.size() >= numActiveBits) {
                    break;
                }
            }
        }
        
        // Stop if we've reached the target number of active bits
        if (indices.size() >= numActiveBits) {
            break;
        }
    }
    
    // Sort indices for better compression
    std::sort(indices.begin(), indices.end());
    
    // Store string length as the first index (shifted to avoid collision)
    // This is crucial for reversibility
    indices.insert(indices.begin(), str.length() + sdrWidth_);
    
    return indices;
}

// Binary data encoding/decoding methods
std::vector<size_t> MetadataSDRStrategy::encodeBinaryData(const std::vector<std::byte>& data) const {
    // For extremely large binary data (like model graph structures), we need to be memory-efficient
    const bool isVeryLargeData = data.size() > 1024 * 1024; // > 1MB
    const bool isSmallData = data.size() < 1024; // < 1KB
    
    std::cerr << "  Binary data size: " << data.size() << " bytes" << std::endl;
    
    // For very large data, use direct storage instead of SDR encoding
    // This prevents memory issues while preserving reversibility
    if (isVeryLargeData) {
        std::cerr << "  Using memory-efficient encoding for large binary data" << std::endl;
        
        // Use a special flag (sdrWidth_ value) to indicate this is using direct storage
        // This will be checked in decodeBinaryData
        std::vector<size_t> specialIndices;
        specialIndices.push_back(sdrWidth_); // Special marker
        specialIndices.push_back(data.size()); // Store original size
        
        // Don't return the actual data here - will be handled specially in compress()
        return specialIndices;
    }
    
    // For small and medium data, use more efficient encoding
    
    // Use more efficient sparsity for different data sizes
    float effectiveSparsity;
    if (isSmallData) {
        effectiveSparsity = sparsity_ * 0.5f; // Lower sparsity for small data
    } else {
        // Scale sparsity down for larger data to prevent memory explosion
        effectiveSparsity = std::max(0.005f, sparsity_ * (1.0f - std::min(0.9f, data.size() / (10.0f * 1024 * 1024))));
    }
    
    // Determine target active bits with a cap to prevent memory issues
    size_t maxActiveBits = std::min(size_t(100000), static_cast<size_t>(sdrWidth_ * effectiveSparsity));
    size_t numActiveBits = std::max(size_t(16), std::min(maxActiveBits, static_cast<size_t>(data.size() * 2 * effectiveSparsity)));
    
    std::cerr << "  Using sparsity: " << effectiveSparsity << ", target bits: " << numActiveBits << std::endl;
    
    // Reserve space for indices with a reasonable capacity
    std::vector<size_t> indices;
    indices.reserve(std::min(numActiveBits + 100, data.size()));
    
    // Store data size at the beginning (shifted to avoid collision)
    indices.push_back(data.size() + sdrWidth_);
    
    // For very small data, use a more direct encoding approach
    if (isSmallData && data.size() < 100) {
        // For extremely small data, just store direct byte values with minimal encoding
        for (size_t i = 0; i < data.size(); i++) {
            uint8_t byte = static_cast<uint8_t>(data[i]);
            
            // Encode byte position and value directly
            size_t encodedValue = (i << 8) | byte;
            size_t index = encodedValue % sdrWidth_;
            
            indices.push_back(index);
            
            // Add a second index for redundancy/error correction
            size_t secondIndex = ((i + 1) * 256 + byte) % sdrWidth_;
            if (secondIndex != index) { // Avoid duplicates
                indices.push_back(secondIndex);
            }
        }
    } else {
        // For medium-sized data, use a memory-efficient sampling approach
        // Divide data into chunks and sample from each chunk
        const size_t chunkSize = std::max(size_t(64), data.size() / 1000);
        const size_t numChunks = (data.size() + chunkSize - 1) / chunkSize;
        
        // Calculate samples per chunk to distribute indices evenly
        size_t samplesPerChunk = std::max(size_t(1), numActiveBits / numChunks);
        
        // Process each chunk with limited memory usage
        for (size_t chunkIndex = 0; chunkIndex < numChunks; chunkIndex++) {
            size_t chunkStart = chunkIndex * chunkSize;
            size_t chunkEnd = std::min(chunkStart + chunkSize, data.size());
            
            // Use a hash of the chunk to determine sampling pattern
            uint32_t chunkHash = chunkIndex * 31337;
            
            // Sample bytes from the chunk based on the hash
            for (size_t i = 0; i < samplesPerChunk && indices.size() < numActiveBits; i++) {
                // Deterministic sampling within the chunk
                size_t offset = (chunkHash + i * 97) % chunkSize;
                size_t position = chunkStart + (offset % (chunkEnd - chunkStart));
                
                if (position < data.size()) {
                    uint8_t byte = static_cast<uint8_t>(data[position]);
                    
                    // Create a unique index based on position and value
                    size_t index = ((position * 256) + byte) % sdrWidth_;
                    indices.push_back(index);
                    
                    // Update hash for next iteration
                    chunkHash = chunkHash * 31 + byte;
                }
            }
            
            // Add chunk boundary marker for every N chunks
            if (chunkIndex % 10 == 0) {
                size_t boundaryIndex = (chunkIndex * sdrWidth_ / numChunks) % sdrWidth_;
                indices.push_back(boundaryIndex);
            }
        }
    }
    
    // If we have too few indices, add some additional ones based on data checksum
    if (indices.size() < 16) {
        uint32_t checksum = 0;
        for (size_t i = 0; i < std::min(data.size(), size_t(1000)); i++) {
            checksum = checksum * 31 + static_cast<uint8_t>(data[i]);
        }
        
        // Add a few indices based on checksum for redundancy
        for (int i = 0; i < 4 && indices.size() < 16; i++) {
            indices.push_back((checksum + i * 1009) % sdrWidth_);
        }
    }
    
    // Remove duplicates and sort, but limit the vector operations to prevent OOM
    if (indices.size() > 1) {
        std::sort(indices.begin(), indices.end());
        
        // Manual duplicate removal to reduce memory operations
        std::vector<size_t> uniqueIndices;
        uniqueIndices.reserve(indices.size());
        
        size_t lastValue = indices[0];
        uniqueIndices.push_back(lastValue);
        
        for (size_t i = 1; i < indices.size(); i++) {
            if (indices[i] != lastValue) {
                lastValue = indices[i];
                uniqueIndices.push_back(lastValue);
            }
        }
        
        return uniqueIndices;
    }
    
    return indices;
}

std::vector<std::byte> MetadataSDRStrategy::decodeBinaryData(const std::vector<size_t>& indices, size_t originalSize) const {
    if (indices.empty()) {
        return std::vector<std::byte>();
    }
    
    // First index should be the data size + sdrWidth_
    size_t dataSize = indices[0] - sdrWidth_;
    
    // If the data size doesn't match, use the provided originalSize
    if (dataSize != originalSize) {
        dataSize = originalSize;
    }
    
    // Determine if we're using the small data format (<100 bytes)
    const bool isSmallData = dataSize < 100;
    
    std::vector<std::byte> result(dataSize, std::byte(0));
    
    // Create a lookup table for which indices are active
    std::unordered_map<size_t, bool> activeIndices;
    for (size_t i = 1; i < indices.size(); i++) {  // Skip the first index (size)
        activeIndices[indices[i]] = true;
    }
    
    // For small data, we used a more direct encoding
    if (isSmallData) {
        // First, check for direct position+value encodings
        std::vector<bool> byteFound(dataSize, false);
        
        // For each possible byte position and value
        for (size_t i = 0; i < dataSize; i++) {
            bool foundMatch = false;
            std::vector<uint8_t> candidates;
            
            // Check both position-specific indices for each possible byte value
            for (uint16_t b = 0; b < 256; b++) {
                // Primary index check
                size_t encodedValue = (i << 8) | b;
                size_t index = encodedValue % sdrWidth_;
                
                // Secondary index check
                size_t secondIndex = ((i + 1) * 256 + b) % sdrWidth_;
                
                // If either index is active, this is a candidate
                if (activeIndices[index] || activeIndices[secondIndex]) {
                    candidates.push_back(static_cast<uint8_t>(b));
                    
                    // If both indices are active, this is very likely the correct byte
                    if (activeIndices[index] && activeIndices[secondIndex]) {
                        result[i] = static_cast<std::byte>(b);
                        byteFound[i] = true;
                        foundMatch = true;
                        break;
                    }
                }
            }
            
            // If we didn't find a perfect match but have candidates, use the first one
            if (!foundMatch && !candidates.empty()) {
                result[i] = static_cast<std::byte>(candidates[0]);
                byteFound[i] = true;
            }
        }
        
        // For any bytes we couldn't find directly, make a best guess
        for (size_t i = 0; i < dataSize; i++) {
            if (!byteFound[i]) {
                // Just copy from adjacent byte as a fallback
                if (i > 0) {
                    result[i] = result[i-1];
                } else if (i < dataSize - 1) {
                    result[i] = result[i+1];
                }
            }
        }
    } else {
        // For larger data, we need to handle the more complex encoding
        for (size_t i = 0; i < dataSize; i++) {
            // Start with a score-based approach for each possible byte
            std::vector<int> scores(256, 0);
            uint8_t bestByte = 0;
            int bestScore = -1;
            
            // Check for high-value bytes with bit-level encoding
            for (uint16_t candidateByte = 128; candidateByte < 256; candidateByte++) {
                int bitMatches = 0;
                int bitTotal = 0;
                
                for (int bit = 0; bit < 8; bit++) {
                    if ((candidateByte >> bit) & 0x01) {
                        bitTotal++;
                        size_t bitIndex = (i * 8 + bit) % sdrWidth_;
                        if (activeIndices[bitIndex]) {
                            bitMatches++;
                        }
                    }
                }
                
                // Score based on bit match ratio
                if (bitTotal > 0) {
                    scores[candidateByte] += (bitMatches * 10) / bitTotal;
                }
            }
            
            // Check for direct byte index (for low-value bytes)
            for (uint16_t candidateByte = 0; candidateByte < 128; candidateByte++) {
                size_t byteIndex = (i * 256 + candidateByte) % sdrWidth_;
                if (activeIndices[byteIndex]) {
                    scores[candidateByte] += 20;  // Direct match is high confidence
                }
            }
            
            // Check position index (for every 4th byte)
            if (i % 4 == 0) {
                for (uint16_t candidateByte = 0; candidateByte < 256; candidateByte++) {
                    size_t positionIndex = ((i * 257) + (candidateByte * 53)) % sdrWidth_;
                    if (activeIndices[positionIndex]) {
                        scores[candidateByte] += 15;  // Position index is good confidence
                    }
                }
            }
            
            // Find the byte with the highest score
            for (uint16_t b = 0; b < 256; b++) {
                if (scores[b] > bestScore) {
                    bestScore = scores[b];
                    bestByte = static_cast<uint8_t>(b);
                }
            }
            
            // If we have a reasonable score, use this byte
            if (bestScore > 0) {
                result[i] = static_cast<std::byte>(bestByte);
            } else {
                // As a fallback, if we can't decode a byte, use a nearby known value
                // This shouldn't happen often with our encoding redundancy
                if (i > 0) {
                    result[i] = result[i-1];
                }
            }
        }
    }
    
    return result;
}

std::string MetadataSDRStrategy::decodeString(const std::vector<size_t>& indices) const {
    if (indices.empty()) {
        return "";
    }
    
    // First index contains the string length (shifted by sdrWidth_)
    size_t strLength = indices[0] - sdrWidth_;
    
    // Create a lookup table of which indices are active
    std::unordered_map<size_t, bool> activeIndices;
    for (size_t i = 1; i < indices.size(); i++) {  // Skip the first index (length)
        activeIndices[indices[i]] = true;
    }
    
    // Reconstruct the string by checking which character/position combinations
    // would have generated the active indices
    std::string result;
    result.reserve(strLength);
    
    for (size_t i = 0; i < strLength; i++) {
        // Try each possible character
        for (unsigned char c = 32; c < 127; c++) {  // Printable ASCII range
            int matchCount = 0;
            
            // Check if the indices this character would generate are active
            for (size_t j = 0; j < 4; j++) {
                size_t hash = (c * 31 + i) * 17 + j * 257;
                size_t index = hash % sdrWidth_;
                
                if (activeIndices[index]) {
                    matchCount++;
                }
            }
            
            // If most indices match, this is likely the correct character
            if (matchCount >= 2) {  // Threshold for match
                result.push_back(c);
                break;
            }
        }
        
        // If we couldn't find a match, add a placeholder
        if (result.length() <= i) {
            result.push_back('?');
        }
    }
    
    return result;
}

} // namespace CortexAICompression
